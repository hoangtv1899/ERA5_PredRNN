2022-10-06 20:15:09.727139: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home1/08589/hvtran/.local/lib/python3.9/site-packages/cv2/../../lib64:/opt/apps/pmix/3.2.3/lib:/opt/apps/intel19/python3/3.9.7/lib:/opt/intel/compilers_and_libraries_2020.4.304/linux/mpi/intel64/libfabric/lib:/opt/intel/compilers_and_libraries_2020.4.304/linux/mpi/intel64/lib/release:/opt/intel/compilers_and_libraries_2020.4.304/linux/mpi/intel64/lib:/opt/intel/debugger_2020/libipt/intel64/lib:/opt/intel/compilers_and_libraries_2020.1.217/linux/daal/lib/intel64_lin:/opt/intel/compilers_and_libraries_2020.1.217/linux/tbb/lib/intel64_lin/gcc4.8:/opt/intel/compilers_and_libraries_2020.1.217/linux/mkl/lib/intel64_lin:/opt/intel/compilers_and_libraries_2020.1.217/linux/ipp/lib/intel64:/opt/intel/compilers_and_libraries_2020.1.217/linux/compiler/lib/intel64_lin:/opt/apps/gcc/9.4.0/lib64:/opt/apps/gcc/9.4.0/lib:/usr/lib64
2022-10-06 20:15:09.727694: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /home1/08589/hvtran/.local/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth
Namespace(is_training=1, device='cuda', dataset_name='mnist', train_data_paths='/work/08589/hvtran/ls6/ERA5_PredRNN-main/era5_train_09012018_6_24hr.npz,/work/08589/hvtran/ls6/ERA5_PredRNN-main/era5_train_09012017_6_24hr.npz,/work/08589/hvtran/ls6/ERA5_PredRNN-main/era5_train_10012015_6_24hr.npz', valid_data_paths='/work/08589/hvtran/ls6/ERA5_PredRNN-main/era5_train_09012018_6_24hr.npz', save_dir='/work/08589/hvtran/ls6/ERA5_PredRNN-main/predrnn-pytorch/checkpoints/era5_predrnn1', gen_frm_dir='/work/08589/hvtran/ls6/ERA5_PredRNN-main/predrnn-pytorch/checkpoints/era5_predrnn1', input_length=3, total_length=6, img_width=1440, img_height=720, img_channel=6, concurent_step=1, use_weight=1, layer_weight='10,10,10,10,20,20', model_name='predrnn_v2', pretrained_model='/work/08589/hvtran/ls6/ERA5_PredRNN-main/model.ckpt-500', num_hidden='400,400,400,400', filter_size=5, stride=1, patch_size=15, patch_size1=4, layer_norm=1, decouple_beta=0.05, reverse_scheduled_sampling=1, r_sampling_step_1=25000.0, r_sampling_step_2=50000, r_exp_alpha=2500, scheduled_sampling=1, sampling_stop_iter=50000, sampling_start_value=1.0, sampling_changing_rate=2e-05, lr=0.0002, reverse_input=1, batch_size=1, max_iterations=10000, display_interval=5, test_interval=1000000, snapshot_interval=2000, num_save_samples=10, n_gpu=1, visual=0, visual_path='./decoupling_visual', injection_action='concat', conv_on_input=0, res_on_conv=0, num_action_ch=4, is_static=0, is_scale=0, out_scale1='', out_scale2='', in_scale1='', in_scale2='', noise_val=0, out_channel=5, stat_layers=8, stat_layers2=5, out_weights='', curr_best_loss=0.61, isloss=1, is_logscale=0, is_WV=1)
Initializing models
load model: /work/08589/hvtran/ls6/ERA5_PredRNN-main/model.ckpt-500
input_raw_data
(720, 6, 720, 1440)
dims
(1, 3)
clips
(2, 30, 2)
input_raw_data
(720, 6, 720, 1440)
dims
(1, 3)
clips
(2, 30, 2)
/home1/08589/hvtran/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([1, 47, 18, 36, 9600])) that is different to the input size (torch.Size([1, 5, 18, 36, 9600])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
Traceback (most recent call last):
  File "/work/08589/hvtran/ls6/ERA5_PredRNN-main/predrnn-pytorch/run1.py", line 249, in <module>
    train_wrapper(model)
  File "/work/08589/hvtran/ls6/ERA5_PredRNN-main/predrnn-pytorch/run1.py", line 216, in train_wrapper
    trainer.train(model, ims, real_input_flag, args, itr)
  File "/work/08589/hvtran/ls6/ERA5_PredRNN-main/predrnn-pytorch/core/trainer.py", line 14, in train
    cost = model.train(ims, real_input_flag)
  File "/work/08589/hvtran/ls6/ERA5_PredRNN-main/predrnn-pytorch/core/models/model_factory.py", line 43, in train
    next_frames, loss = self.network(frames_tensor, mask_tensor,istrain=istrain)
  File "/home1/08589/hvtran/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/08589/hvtran/ls6/ERA5_PredRNN-main/predrnn-pytorch/core/models/predrnn_v2.py", line 211, in forward
    loss = self.MSE_criterion(next_frames.to('cuda:2')*self.layer_weights.to('cuda:2'), frames_tensor[:,1:,:,:,:].to('cuda:2')*self.layer_weights.to('cuda:2')) + \
  File "/home1/08589/hvtran/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home1/08589/hvtran/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 529, in forward
    return F.mse_loss(input, target, reduction=self.reduction)
  File "/home1/08589/hvtran/.local/lib/python3.9/site-packages/torch/nn/functional.py", line 3261, in mse_loss
    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
  File "/home1/08589/hvtran/.local/lib/python3.9/site-packages/torch/functional.py", line 75, in broadcast_tensors
    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]
RuntimeError: The size of tensor a (5) must match the size of tensor b (47) at non-singleton dimension 1
